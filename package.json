{
  "name": "nexulapi",
  "version": "1.0.0",
  "description": "LLM API for any model. This server is designed to connect other servers to access large AI language models through an universal API.",
  "main": "dist/app.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "build": "npm run ts-to-json && tsc",
    "dev": "npm run ts-to-json && tsc-watch --onSuccess \"node ./dist/app.js\"",
    "start": "npm run ts-to-json && node dist/app.js",
    "ts-to-json": "typescript-json-schema src/routes/chat/chat.interface.ts ChatRequest -0 -o src/schemas/chat/schema.json --required",
    "start:docker": "node app.js"
  },
  "keywords": [
    "llm",
    "api",
    "openai",
    "gpt4free",
    "huggingface",
    "huggingface hub"
  ],
  "author": "artegoser",
  "license": "MIT",
  "devDependencies": {
    "@types/node": "^20.7.2",
    "@typescript-eslint/eslint-plugin": "^6.7.3",
    "@typescript-eslint/parser": "^6.7.3",
    "eslint": "^8.50.0",
    "tsc-watch": "^6.0.4",
    "typescript": "^5.2.2"
  },
  "dependencies": {
    "@fastify/cors": "^8.4.0",
    "axios": "^1.5.1",
    "dotenv": "^16.3.1",
    "fastify": "^4.23.2",
    "openai": "^4.11.0",
    "typescript-json-schema": "^0.61.0"
  }
}
